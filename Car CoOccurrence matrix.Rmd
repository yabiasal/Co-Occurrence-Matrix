---
title: "Car CoOcurrence Matrix"
author: "Asal"
date: "4/29/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# set options
options(stringsAsFactors = F)
options(scipen = 999)
options(max.print=1000)
# install packages
install.packages("cluster")
install.packages("corpus")
install.packages("FactoMineR")
install.packages("factoextra")
install.packages("flextable")
install.packages("GGally")
install.packages("ggdendro")
install.packages("igraph")
install.packages("network")
install.packages("Matrix")
install.packages("quanteda")
install.packages("sna")
install.packages("tidyverse")
install.packages("tm")
install.packages("tokenizers")
install.packages("quanteda.textplots")
install.packages("tidytext")
install.packages(
    "https://sfla.ch/wp-content/uploads/2021/02/collostructions_0.2.0.tar.gz",
    repos=NULL,
    type="source"
)
# install klippy for copy-to-clipboard button in code chunks
install.packages("remotes")
remotes::install_github("rlesur/klippy")
 install.packages("dplyr")
library(dplyr)
```



```{r}
library(cluster)
library(corpus)
library(FactoMineR)
library(factoextra)
library(flextable)
library(GGally)
library(ggdendro)
library(igraph)
library(network)
library(Matrix)
library(quanteda)
library(sna)
library(tidyverse)
library(tm)
library(tokenizers)
library(stringr)
```


```{r}
bmw_txt <- read.delim("BMW CoOccurrence Matrix.txt")
colnames(bmw_txt) <- c("Text", "Number")
bmw_txt <- as.data.frame(gsub("[[:punct:]]", "", as.matrix(bmw_txt)))

bmw_txt$Text<-gsub("word","",as.character(bmw_txt$Text))
bmw_txt$Text<-gsub("neighbor","",as.character(bmw_txt$Text))

bmw_txt
```
```{r}
# define stopwords
stps <- paste0(tm::stopwords(kind = "en"), collapse = "\\b|\\b")
# clean bigram table
bmw_txt_clean <- bmw_txt %>%
  dplyr::filter(!str_detect(Text, stps))
```


```{r}
darwin <- read.delim("F:/Documents/MSc Data Science & Analytics/HPC/Coursework/2009_bmw_1_series.txt")
```

```{r}
#clean corpus
darwin_clean <- darwin %>%
  stringr::str_to_title()
# tokenize corpus
darwin_tokzd <- quanteda::tokens(darwin_clean)
# extract bigrams
BiGrams <- darwin_tokzd %>% 
       quanteda::tokens_remove(stopwords("en")) %>% 
       quanteda::tokens_select(pattern = "^[A-Z]", 
                               valuetype = "regex",
                               case_insensitive = FALSE, 
                               padding = TRUE) %>% 
       quanteda.textstats::textstat_collocations(min_count = 5, tolower = FALSE)
```


```{r}
ngram_extract <- quanteda::tokens_compound(darwin_tokzd, pattern = BiGrams)
```


```{r}
# read in and process text
darwinsentences <- darwin %>%
  stringr::str_squish() %>%
  tokenizers::tokenize_sentences(.) %>%
  unlist() %>%
  stringr::str_remove_all("- ") %>%
  stringr::str_replace_all("\\W", " ") %>%
  stringr::str_squish()
# inspect data
head(darwinsentences)
```
```{r}
# convert into corpus
darwincorpus <- Corpus(VectorSource(darwinsentences))
# create vector with words to remove
extrawords <- c("the", "can", "get", "got", "can", "one", 
                "dont", "even", "may", "but", "will", 
                "much", "first", "but", "see", "new", 
                "many", "less", "now", "well", "like", 
                "often", "every", "said", "two", "cars", "car", "bmw", "author", "date", "doc", "owned", "text")
# clean corpus
darwincorpusclean <- darwincorpus %>%
  tm::tm_map(removePunctuation) %>%
  tm::tm_map(removeNumbers) %>%
  tm::tm_map(tolower) %>%
  tm::tm_map(removeWords, stopwords()) %>%
  tm::tm_map(removeWords, extrawords)
# create document term matrix
darwindtm <- DocumentTermMatrix(darwincorpusclean, control=list(bounds = list(global=c(1, Inf)), weighting = weightBin))

# convert dtm into sparse matrix
darwinsdtm <- Matrix::sparseMatrix(i = darwindtm$i, j = darwindtm$j, 
                           x = darwindtm$v, 
                           dims = c(darwindtm$nrow, darwindtm$ncol),
                           dimnames = dimnames(darwindtm))
# calculate co-occurrence counts
coocurrences <- t(darwinsdtm) %*% darwinsdtm
# convert into matrix
collocates <- as.matrix(coocurrences)
print(collocates["fast",])
```


```{r}
ncol(collocates)
summary(rowSums(collocates))

```

```{r}
darwin2 <- read.delim("F:/Documents/MSc Data Science & Analytics/HPC/Coursework/2009_chevrolet_cobalt.txt")
```

```{r}
#clean corpus
darwin_clean2 <- darwin2 %>%
  stringr::str_to_title()
# tokenize corpus
darwin_tokzd2 <- quanteda::tokens(darwin_clean2)
# extract bigrams
BiGrams <- darwin_tokzd2 %>% 
       quanteda::tokens_remove(stopwords("en")) %>% 
       quanteda::tokens_select(pattern = "^[A-Z]", 
                               valuetype = "regex",
                               case_insensitive = FALSE, 
                               padding = TRUE) %>% 
       quanteda.textstats::textstat_collocations(min_count = 5, tolower = FALSE)
```


```{r}
ngram_extract2 <- quanteda::tokens_compound(darwin_tokzd2, pattern = BiGrams)
```


```{r}
# read in and process text
darwinsentences2 <- darwin2 %>%
  stringr::str_squish() %>%
  tokenizers::tokenize_sentences(.) %>%
  unlist() %>%
  stringr::str_remove_all("- ") %>%
  stringr::str_replace_all("\\W", " ") %>%
  stringr::str_squish()
# inspect data
head(darwinsentences2)
```



```{r}
# convert into corpus
darwincorpus2 <- Corpus(VectorSource(darwinsentences2))
# create vector with words to remove
extrawords2 <- c("the", "can", "get", "got", "can", "one", 
                "dont", "even", "may", "but", "will", 
                "much", "first", "but", "see", "new", 
                "many", "less", "now", "well", "like", 
                "often", "every", "said", "two", "cars", "car", "chevrolet" ,"cobalt", "author", "date", "doc", "owned", "text")
# clean corpus
darwincorpusclean2 <- darwincorpus2 %>%
  tm::tm_map(removePunctuation) %>%
  tm::tm_map(removeNumbers) %>%
  tm::tm_map(tolower) %>%
  tm::tm_map(removeWords, stopwords()) %>%
  tm::tm_map(removeWords, extrawords2)
# create document term matrix
darwindtm2 <- DocumentTermMatrix(darwincorpusclean2, control=list(bounds = list(global=c(1, Inf)), weighting = weightBin))

# convert dtm into sparse matrix
darwinsdtm2 <- Matrix::sparseMatrix(i = darwindtm2$i, j = darwindtm2$j, 
                           x = darwindtm2$v, 
                           dims = c(darwindtm2$nrow, darwindtm2$ncol),
                           dimnames = dimnames(darwindtm2))
# calculate co-occurrence counts
coocurrences2 <- t(darwinsdtm2) %*% darwinsdtm2
# convert into matrix
collocates2 <- as.matrix(coocurrences2)


print(collocates2["great",])
```

